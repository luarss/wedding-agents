# Venue ETL Automation with Claude Agent SDK

Automated ETL pipeline for Singapore wedding venue data using the Claude Agent SDK to orchestrate parallel web searches for data enrichment.

## Overview

This module automates the **Stage 2B enrichment process** from the venue ETL pipeline, eliminating manual web searches and JSON editing.

### Key Innovation: Parallel Web Search Orchestration

The Claude Agent SDK automatically coordinates **6 parallel web searches per venue**, reducing enrichment time from **3 minutes to 30 seconds per venue** (6x faster).

## Quick Start

### Prerequisites

```bash
# Ensure claude-agent-sdk is installed
uv sync

# Set up API key
export ANTHROPIC_API_KEY=your_api_key_here
```

### Basic Usage

```bash
# Run automated enrichment on transformed venues
uv run python -m backend.etl.enrich_venues transformed.json

# Interactive mode (ask before enriching)
uv run python -m backend.etl.enrich_venues transformed.json --interactive

# Enrich first 10 venues only (for testing)
uv run python -m backend.etl.enrich_venues transformed.json --max-venues 10

# Custom confidence threshold
uv run python -m backend.etl.enrich_venues transformed.json --min-confidence 0.8
```

## Architecture

### Components

**1. MCP Tools** (`tools/enrich_tool.py`)

Four specialized tools for enrichment orchestration:

- `get_venues_needing_enrichment`: Identifies venues with low confidence or missing fields
- `generate_enrichment_queries`: Creates 6 optimized search queries per venue
- `consolidate_enrichment_results`: Provides extraction guidance for search results
- `update_venue_data`: Merges enrichment data and recalculates confidence scores

**2. System Prompt** (`prompts/enrichment_agent_prompt.md`)

Detailed instructions for the agent including:
- Parallel search strategy (6 searches per venue in single message)
- Singapore-specific validation rules
- Field extraction guidelines
- Data quality standards

**3. Orchestrator** (`enrich_venues.py`)

Main script that:
- Creates Claude Agent SDK client
- Configures MCP server with enrichment tools
- Orchestrates 3-step enrichment workflow
- Provides CLI interface

### Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: Identify Venues Needing Enrichment                 â”‚
â”‚  â†’ get_venues_needing_enrichment tool                       â”‚
â”‚  â†’ Returns venues with confidence < 0.7                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: Enrich Each Venue with Parallel Searches           â”‚
â”‚  For each venue:                                            â”‚
â”‚    1. generate_enrichment_queries â†’ 6 search queries       â”‚
â”‚    2. Launch 6 WebSearch calls in PARALLEL (single message)â”‚
â”‚    3. consolidate_enrichment_results â†’ extraction guidance â”‚
â”‚    4. Extract data from all 6 search results               â”‚
â”‚    5. update_venue_data â†’ merge + save                     â”‚
â”‚  â†’ Repeat for all venues                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: Generate Final Report                              â”‚
â”‚  â†’ Completeness statistics                                  â”‚
â”‚  â†’ Before/after comparison                                  â”‚
â”‚  â†’ Remaining venues needing enrichment                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Parallel Search Strategy

### Why Parallel Searches Matter

**Sequential searches (OLD):**
```
Search 1 â†’ Wait â†’ Search 2 â†’ Wait â†’ Search 3 â†’ Wait...
Total time: 6 Ã— 30s = 3 minutes per venue
```

**Parallel searches (NEW):**
```
Search 1 â”
Search 2 â”œâ”€ All launched simultaneously in ONE message
Search 3 â”œâ”€ Wait for ALL results together
Search 4 â”œâ”€ Then consolidate
Search 5 â”œâ”€
Search 6 â”˜
Total time: ~30 seconds per venue
```

### Search Query Types

For each venue, 6 specialized queries are generated:

1. **Pricing**: Wedding ballroom pricing per table (2024-2025)
2. **Contact**: Phone, email, address, postal code
3. **Capacity**: Guest count, minimum/maximum capacity
4. **Amenities**: Packages, features, bridal suite, facilities
5. **Reviews**: Rating, review count, testimonials
6. **Location**: MRT station, distance, accessibility

## Integration with Existing ETL Pipeline

This automation integrates with the existing `.claude/skills/venue-etl-pipeline`:

### Before (Manual)

```bash
# Stage 1: Extract
python scripts/extract_venues.py input.csv --source "Bridely"

# Stage 2A: Transform (automated)
python scripts/transform_venues.py extracted.json

# Stage 2B: Transform (MANUAL - 3 min per venue)
# â†’ Manually identify venues needing enrichment
# â†’ Manually run 6 web searches per venue
# â†’ Manually consolidate results
# â†’ Manually edit JSON files
# â†’ Repeat for 50+ venues (2.5+ hours!)

# Stage 3: Deduplicate
python scripts/deduplicate_venues.py transformed.json

# Stage 4: Load
python scripts/load_venues.py deduplicated.json --merge
```

### After (Automated)

```bash
# Stage 1: Extract
python scripts/extract_venues.py input.csv --source "Bridely"

# Stage 2A: Transform (automated)
python scripts/transform_venues.py extracted.json

# Stage 2B: Transform (AUTOMATED - 30 sec per venue)
uv run python -m backend.etl.enrich_venues transformed.json

# Stage 3: Deduplicate
python scripts/deduplicate_venues.py transformed.json

# Stage 4: Load
python scripts/load_venues.py deduplicated.json --merge
```

**Time saved**: 2.5 hours â†’ 25 minutes for 50 venues!

## Field Extraction Guidelines

The agent extracts the following fields from search results:

### Critical Fields (40% weight)
- `pricing.price_per_table` (int)
- `pricing.pricing_type` (str): "plus_plus" or "nett"
- `capacity.max_capacity` (int)

### High Priority Fields (30% weight)
- `location.address` (str)
- `location.zone` (str): Inferred from postal code
- `contact.phone` (str): Formatted as "+65 XXXX XXXX"
- `contact.email` (str)

### Medium Priority Fields (20% weight)
- `location.nearest_mrt` (str)
- `location.mrt_distance` (str)
- `amenities.*` (boolean flags)
- `rating` (float)

### Low Priority Fields (10% weight)
- `contact.website` (str)
- `restrictions.*`

## Data Quality Rules

### âœ… DO:
- Use parallel searches (6 per venue in single message)
- Prefer official venue websites
- Cross-validate data from multiple sources
- Note year/date of pricing information
- Leave fields empty if no reliable data found
- Format phone numbers as "+65 XXXX XXXX"
- Infer zone from postal code

### âŒ DON'T:
- Use sequential searches (6x slower)
- Fabricate or guess missing data
- Use pricing older than 2 years
- Use non-official sources for pricing
- Batch updates without saving incrementally

## Singapore-Specific Context

### Pricing Types
- **"plus_plus"**: Base price + 9% GST + 10% service charge
- **"nett"**: All-inclusive pricing

### Postal Code â†’ Zone Mapping
- 01-28, 78 â†’ Central
- 29-48 â†’ East
- 49-55, 79-80 â†’ North
- 60-77 â†’ West

### Common MRT Lines
NS (North-South), EW (East-West), CC (Circle), DT (Downtown), TE (Thomson-East Coast)

## Progress Tracking

The agent reports progress every 5 venues:

```
ğŸ“Š Progress Update:
- Venues enriched: 15/48
- Average confidence: 0.35 â†’ 0.78
- Still needing enrichment: 33 venues
- Time per venue: ~30 seconds
```

## Error Handling & Resume

**Incremental saving**: Each venue is saved immediately after enrichment, so progress is never lost.

**Interrupt recovery**: If interrupted (Ctrl+C), simply run the script again. It will only enrich venues still below the confidence threshold.

```bash
# If interrupted during enrichment
^C
âš ï¸  Enrichment interrupted by user.
ğŸ’¡ Progress is saved incrementally. You can resume by running the script again.

# Resume by running again
uv run python -m backend.etl.enrich_venues transformed.json
# Will only process remaining venues
```

## Examples

### Example 1: Full Automated Enrichment

```bash
# Enrich all venues with confidence < 0.7
uv run python -m backend.etl.enrich_venues pipeline_runs/2025-01-22/transformed.json

# Output:
# ğŸš€ Starting venue enrichment with Claude Agent SDK
# ğŸ“‚ Input file: pipeline_runs/2025-01-22/transformed.json
# ğŸ¯ Target confidence: 0.7
# ğŸ”„ Mode: Automated
#
# ğŸ“Š Step 1: Identifying venues needing enrichment...
# ğŸ” Found 48 venues needing enrichment (96.0%)
#
# âš¡ Step 2: Enriching venues with parallel web searches...
# âœ… Updated venue: Grand Hyatt Singapore (0.35 â†’ 0.92)
# âœ… Updated venue: Raffles Hotel (0.42 â†’ 0.88)
# ...
# ğŸ“Š Progress Update: 15/48 venues enriched, avg confidence 0.78
# ...
#
# ğŸ“ˆ Step 3: Generating final report...
# âœ… Enrichment complete! 48 venues enriched, avg confidence 0.85
```

### Example 2: Interactive Mode (Testing)

```bash
# Ask before enriching
uv run python -m backend.etl.enrich_venues transformed.json --interactive --max-venues 3

# Output:
# ğŸ“Š Step 1: Identifying venues needing enrichment...
# ğŸ” Found 48 venues needing enrichment
#
# Proceed with automated enrichment? This will use parallel web searches for each venue. (y/n): y
#
# âš¡ Step 2: Enriching venues with parallel web searches...
# [Enriches first 3 venues]
```

## Troubleshooting

**Issue**: Agent not using parallel searches
- **Cause**: System prompt not loaded correctly
- **Solution**: Check that `prompts/enrichment_agent_prompt.md` exists and is readable

**Issue**: File permission errors
- **Cause**: Permission mode set to "acceptEdits"
- **Solution**: Use `permission_mode="default"` to require approval for writes

**Issue**: Rate limiting from web searches
- **Cause**: Too many parallel requests
- **Solution**: The agent automatically handles this with the 6-query limit per venue

**Issue**: Low data quality after enrichment
- **Cause**: Non-official sources used
- **Solution**: Review system prompt to emphasize official venue websites

## Performance Metrics

Typical performance for 50 venues:

| Metric | Value |
|--------|-------|
| **Time per venue** | ~30 seconds |
| **Total time (50 venues)** | ~25 minutes |
| **Speedup vs manual** | 6x faster |
| **Confidence improvement** | 0.35 â†’ 0.85 avg |
| **Field completeness** | 35% â†’ 87% |
| **API calls per venue** | 7-8 (6 searches + tool calls) |

## Next Steps

After enrichment, continue with the standard ETL pipeline:

```bash
# Stage 3: Deduplicate
python scripts/deduplicate_venues.py transformed.json --output deduplicated.json

# Stage 4: Load
python scripts/load_venues.py deduplicated.json --merge --venues-file backend/data/venues.json
```

## Contributing

To extend the enrichment tools:

1. Add new tools to `tools/enrich_tool.py`
2. Register tools in `create_enrichment_server()`
3. Update system prompt in `prompts/enrichment_agent_prompt.md`
4. Test with `--max-venues 1` for single venue testing

## License

Part of the wedding-agent project. See main README for license.
